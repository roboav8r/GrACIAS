{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa8bdfe5-2656-4e1a-8d0e-97241e5496b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0 torchtext==0.16.0+cpu torchdata==0.7.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# pacmd list sources\n",
    "# name: <alsa_input.usb-SEEED_ReSpeaker_4_Mic_Array__UAC1.0_-00.multichannel-input>\n",
    "#         driver: <module-alsa-card.c>\n",
    "#         flags: HARDWARE DECIBEL_VOLUME LATENCY DYNAMIC_LATENCY\n",
    "#         state: SUSPENDED\n",
    "#         suspend cause: IDLE\n",
    "#         priority: 9540\n",
    "#         volume: front-left: 65536 / 100% / 0.00 dB,   front-right: 65536 / 100% / 0.00 dB,   rear-left: 65536 / 100% / 0.00 dB,   rear-right: 65536 / 100% / 0.00 dB,   front-center: 65536 / 100% / 0.00 dB,   lfe: 65536 / 100% / 0.00 dB\n",
    "#                 balance 0.00\n",
    "#         base volume: 65536 / 100% / 0.00 dB\n",
    "#         volume steps: 65537\n",
    "#         muted: no\n",
    "#         current latency: 0.00 ms\n",
    "#         max rewind: 0 KiB\n",
    "#         sample spec: s16le 6ch 16000Hz\n",
    "#         channel map: front-left,front-right,rear-left,rear-right,front-center,lfe\n",
    "#                      Surround 5.1\n",
    "#         used by: 0\n",
    "#         linked by: 0\n",
    "#         configured latency: 0.00 ms; range is 0.50 .. 2000.00 ms\n",
    "#         card: 4 <alsa_card.usb-SEEED_ReSpeaker_4_Mic_Array__UAC1.0_-00>\n",
    "#         module: 27\n",
    "#         properties:\n",
    "#                 alsa.resolution_bits = \"16\"\n",
    "#                 device.api = \"alsa\"\n",
    "#                 device.class = \"sound\"\n",
    "#                 alsa.class = \"generic\"\n",
    "#                 alsa.subclass = \"generic-mix\"\n",
    "#                 alsa.name = \"USB Audio\"\n",
    "#                 alsa.id = \"USB Audio\"\n",
    "#                 alsa.subdevice = \"0\"\n",
    "#                 alsa.subdevice_name = \"subdevice #0\"\n",
    "#                 alsa.device = \"0\"\n",
    "#                 alsa.card = \"4\"\n",
    "#                 alsa.card_name = \"ReSpeaker 4 Mic Array (UAC1.0)\"\n",
    "#                 alsa.long_card_name = \"SEEED ReSpeaker 4 Mic Array (UAC1.0) at usb-0000:02:00.0-3, full speed\"\n",
    "#                 alsa.driver_name = \"snd_usb_audio\"\n",
    "#                 device.bus_path = \"pci-0000:02:00.0-usb-0:3:1.0\"\n",
    "#                 sysfs.path = \"/devices/pci0000:00/0000:00:01.3/0000:02:00.0/usb1/1-3/1-3:1.0/sound/card4\"\n",
    "#                 udev.id = \"usb-SEEED_ReSpeaker_4_Mic_Array__UAC1.0_-00\"\n",
    "#                 device.bus = \"usb\"\n",
    "#                 device.vendor.id = \"2886\"\n",
    "#                 device.vendor.name = \"Seeed Technology Co., Ltd.\"\n",
    "#                 device.product.id = \"0018\"\n",
    "#                 device.product.name = \"ReSpeaker 4 Mic Array (UAC1.0)\"\n",
    "#                 device.serial = \"SEEED_ReSpeaker_4_Mic_Array__UAC1.0_\"\n",
    "#                 device.form_factor = \"speaker\"\n",
    "#                 device.string = \"hw:4\"\n",
    "#                 device.buffering.buffer_size = \"384000\"\n",
    "#                 device.buffering.fragment_size = \"192000\"\n",
    "#                 device.access_mode = \"mmap+timer\"\n",
    "#                 device.profile.name = \"multichannel-input\"\n",
    "#                 device.profile.description = \"Multichannel\"\n",
    "#                 device.description = \"ReSpeaker 4 Mic Array (UAC1.0) Multichannel\"\n",
    "#                 module-udev-detect.discovered = \"1\"\n",
    "#                 device.icon_name = \"audio-speakers-usb\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b526bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torchaudio.io import StreamReader\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edbc920e-b552-4f1a-bdde-d25cf365bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(q, format, src, segment_length, sample_rate):\n",
    "    \n",
    "    print(\"Building StreamReader...\")\n",
    "    streamer = torchaudio.io.StreamReader(src=src, format=format, option=option)\n",
    "    streamer.add_basic_audio_stream(frames_per_chunk=segment_length, sample_rate=sample_rate, format=\"s16p\", num_channels=6)\n",
    "\n",
    "    print(streamer.get_src_stream_info(0))\n",
    "    print(\"Streaming...\")\n",
    "    print()\n",
    "    for (chunk_a) in streamer.stream(timeout=-1, backoff=1.0):\n",
    "        q.put([chunk_a])\n",
    "\n",
    "\n",
    "class ContextCacher:\n",
    "    \"\"\"Cache the end of input data and prepend the next input data with it.\n",
    "\n",
    "    Args:\n",
    "        segment_length (int): The size of main segment.\n",
    "            If the incoming segment is shorter, then the segment is padded.\n",
    "        context_length (int): The size of the context, cached and appended.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_length: int, context_length: int):\n",
    "        self.segment_length = segment_length\n",
    "        self.context_length = context_length\n",
    "        self.context = torch.zeros([context_length])\n",
    "\n",
    "    def __call__(self, chunk: torch.Tensor):\n",
    "        if chunk.size(0) < self.segment_length:\n",
    "            chunk = torch.nn.functional.pad(chunk, (0, self.segment_length - chunk.size(0)))\n",
    "        chunk_with_context = torch.cat((self.context, chunk))\n",
    "        self.context = chunk[-self.context_length :]\n",
    "        return chunk_with_context\n",
    "\n",
    "class Pipeline:\n",
    "    \"\"\"Build inference pipeline from RNNTBundle.\n",
    "\n",
    "    Args:\n",
    "        bundle (torchaudio.pipelines.RNNTBundle): Bundle object\n",
    "        beam_width (int): Beam size of beam search decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bundle: torchaudio.pipelines.RNNTBundle, beam_width: int = 10):\n",
    "        self.bundle = bundle\n",
    "        self.feature_extractor = bundle.get_streaming_feature_extractor()\n",
    "        self.decoder = bundle.get_decoder()\n",
    "        self.token_processor = bundle.get_token_processor()\n",
    "\n",
    "        self.beam_width = beam_width\n",
    "\n",
    "        self.state = None\n",
    "        self.hypotheses = None\n",
    "\n",
    "    def infer(self, segment: torch.Tensor) -> str:\n",
    "        \"\"\"Perform streaming inference\"\"\"\n",
    "        features, length = self.feature_extractor(segment)\n",
    "        self.hypotheses, self.state = self.decoder.infer(\n",
    "            features, length, self.beam_width, state=self.state, hypothesis=self.hypotheses\n",
    "        )\n",
    "        transcript = self.token_processor(self.hypotheses[0][0], lstrip=False)\n",
    "        return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "345e7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Parameters\n",
    "    device = \"alsa\"\n",
    "    src = \"hw:4\"\n",
    "    n_channels = 6\n",
    "    \n",
    "    # Model info\n",
    "    bundle=torchaudio.pipelines.EMFORMER_RNNT_BASE_LIBRISPEECH\n",
    "    sample_rate = bundle.sample_rate\n",
    "    segment_length = bundle.segment_length * bundle.hop_length\n",
    "    context_length = bundle.right_context_length * bundle.hop_length\n",
    "    pipeline = Pipeline(bundle)\n",
    "    \n",
    "    \n",
    "    # Cache stream\n",
    "    cacher = ContextCacher(segment_length, context_length)\n",
    "    \n",
    "    \n",
    "    # Inference\n",
    "    \n",
    "    ctx = mp.get_context(\"spawn\")\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def infer():\n",
    "        while True:\n",
    "            chunk = q.get()      \n",
    "            segment = cacher(chunk[:, 0])\n",
    "            transcript = pipeline.infer(segment)\n",
    "            print(transcript, end=\"\\r\", flush=True)\n",
    "    \n",
    "    q = ctx.Queue()\n",
    "    p = ctx.Process(target=stream, args=(q, device, src, segment_length, sample_rate))\n",
    "    p.start()\n",
    "    infer()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df1755-f2d4-46f4-98c6-cdcd33d404d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jd/anaconda3/envs/marmot/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jd/anaconda3/envs/marmot/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'stream' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b1a53c3-6353-455f-b88b-a53984377a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "hop length: 160 \n",
      "segment length: 16 \n",
      "context length: 4 \n",
      "2560\n",
      "640\n",
      "<torchaudio.io._stream_reader.StreamReader object at 0x77951405ba60>\n"
     ]
    }
   ],
   "source": [
    "print(sample_rate)\n",
    "print(\"hop length: %s \" % bundle.hop_length)\n",
    "print(\"segment length: %s \" % bundle.segment_length)\n",
    "print(\"context length: %s \" %bundle.right_context_length)\n",
    "print(segment_length)\n",
    "print(context_length)\n",
    "\n",
    "print(streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e2b84-501e-44e4-a862-3bdadf7dfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stream\n",
    "\n",
    "\n",
    "# Visualize stream?\n",
    "\n",
    "\n",
    "# form beam at location (az/el/dist)\n",
    "\n",
    "\n",
    "# visualize separated beam\n",
    "\n",
    "\n",
    "# extract noise/common spectrum from all channels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
