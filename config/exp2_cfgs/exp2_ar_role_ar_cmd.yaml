/**:
  ros__parameters:
    use_sim_time: true
    tracker_frame: 'philbart/base_link'
    mic_frame: 'philbart/base_link'
    artag_frame: 'oak_rgb_camera_optical_frame'
    

### UNIMODAL PROCESSING - VISION
oak:
  ros__parameters:
    camera:
      i_enable_imu: true
      i_enable_ir: true
      i_nn_type: spatial
      i_pipeline_type: RGBD
    stereo:
      i_subpixel: true
    nn:
      i_nn_config_path: depthai_ros_driver/yolo
      i_disable_resize: true
    rgb:
      i_preview_size: 416

depthai_img_preproc_node:
  ros__parameters:
    nn_img_size: 416
    detector_frame: 'oak_rgb_camera_optical_frame'
    labels: ["person", "bicycle","car","motorbike","aeroplane","bus","train","truck","boat","traffic light","fire hydrant","stop sign","parking meter","bench","bird","cat","dog","horse","sheep","cow","elephant","bear","zebra","giraffe","backpack","umbrella","handbag","tie","suitcase","frisbee","skis","snowboard","sports ball","kite","baseball bat","baseball glove","skateboard","surfboard","tennis racket","bottle","wine glass","cup","fork","knife","spoon","bowl","banana","apple","sandwich","orange","broccoli","carrot","hot dog","pizza","donut","cake","chair","sofa","pottedplant","bed","diningtable","toilet","tvmonitor","laptop","mouse","remote","keyboard","cell phone","microwave","oven","toaster","sink","refrigerator","book","clock","vase","scissors","teddy bear","hair drier","toothbrush"]

clip_scene_rec:
  ros__parameters:
    num_est_interval_samples: 15
    scene_labels: ['campus','courtyard','lab','lobby']
    scene_descriptions: ['a picture of a public outdoor area with high social activity',
                         'a picture of a private outdoor area with low social activity',
                         'a picture of a private indoor area with low social activity',
                         'a picture of a public indoor area with high social activity']
    clip_model: 'ViT-L/14'

clip_vis_rec_server:
  ros__parameters:
    clip_model: 'ViT-L/14'
    object_classes: ['person']

    person:
      attributes:
        variables: ['']

      states:
        variables: ['role']
        role:
          labels: ['unknown','pedestrian','robot-teammate','robot-supervisor']
          descriptions: ['', 
                         'a picture of a person', 
                         'a picture of a person wearing a university of texas robotics shirt and orange texas hat', 
                         'a picture of a person wearing a university of texas robotics shirt and orange texas hat and a yellow safety vest']
          probs: [10., 1., 1., 1.]
          sensor_model_coeffs: [.55, .15, .15, .15,
                                .1, .7, .1, .1,
                                .1, .1, .7, .1,
                                .1, .1, .1, .7]
          update_method: 'time'
          update_threshold: .5
      
      comms:
        labels: ['']
        gesture_descriptions: ['']
        probs: []
        # p(command_detected|command_issued)
        gesture_sensor_model_coeffs: []        
        verbal_sensor_model_coeffs: []

### UNIMODAL PROCESSING - AUDITION
/**:
  ros__parameters:

    # General audio params / time domain
    n_total_channels: 16
    channel_indices_used: [0, 1, 2, 3, 4, 5, 6, 7]
    sample_rate: 44100
    hop_size: 44100
    frame_size: 44100 # publish 1 second every second
    speed_sound: 343.
    microphone_frame_id: 'philbart/base_link'
    
    # Frequency domain processing
    n_fft: 512
    n_sources: 2
    f_min: 300
    f_max: 8000

audio_acq_node:
  ros__parameters:

    # Signal acquisition
    src: 'plughw:1,0'
    codec: 'pcm_s16le'

pra_node:
  ros__parameters:

    # Sound source localization
    doa_dimension: 2
    array_x_pos: [0.43, 0.43, -0.34, -0.34, 0., 0., 0., 0.]
    array_y_pos: [-0.28, 0.28, 0.30, -0.30, -0.29, 0.29, -0.11, 0.11]
    array_z_pos: [0.395, 0.395, 0.395, 0.395, 0.610, 0.610, 0.660, 0.660]
    ssl_algo: 'MUSIC'

directional_speech_rec_node:
  ros__parameters:

    # Speech activity detection & recognition
    n_silent_frames: 2
    trigger_level: 3.0
    trigger_time: 0.25
    search_time: 0.25
    allowed_gap: 0.25
    pre_trigger_time: 0.25
    min_voice_samples: 31200
    src_match_thresh_rad: .175 # .5 = ~28.6 degrees # .175 rad = ~10 degrees
    lexicon_package: 'ros_audition'
    lexicon_file: 'config/rocog_lexicon.txt'


### MULTIMODAL PROCESSING - SCENE RECOGNITION
/bayes_fused_scene_est:
  ros__parameters:

    scene_labels: ['campus','courtyard','lab','lobby']
    scene_prior: [.25,.25,.25,.25]

    sensor_names: ['clip','dcase23']

    clip:
      obs_labels: ['campus','courtyard','lab','lobby']
      sensor_model_coeffs: [35272., 3382., 1., 1.,
                            154., 42755., 1., 1.,
                            1., 54., 41930., 211.,
                            1., 15., 4906., 36521.]
      topic: 'clip_scene_category'

    dcase23:
      obs_labels: ['airport', 'bus', 'metro', 'metro_station','park','public_square','shopping_mall','street_pedestrian','street_traffic','tram']
      sensor_model_coeffs: [8., 17., 49., 22., 191., 7., 1., 1., 44., 1948.,
                            4., 305., 5., 8., 765., 1., 1., 2., 22., 1362.,
                            22., 156., 2125., 33., 79., 2., 1., 2., 66., 21.,
                            457., 57., 205., 481., 977., 2., 70., 17., 20., 166.]
      topic: 'audio_scene_category'


### MULTIMODAL PROCESSING - SEMANTIC FUSION NODE
semantic_fusion_node:
  ros__parameters:

    loop_time_sec: 0.5

    role_rec_method: 'artag'
    command_rec_method: 'artag'

    sensor_names: ['artag']
    sensor_symbol: 'z' # Letter to uniquely identify the variable in GTSAM.
    sensors:
      artag:
        type: 'artag'
        topic: 'ar_pose_marker'

        update_method: 'count' # time, count, or confidence
        update_threshold: 4 # Update every 3 messages received

        match_threshold: 0.5

        # How to interpret each AR tag id
        ar_tag_ids: [1,2,3,4,5,6,8,9,10,11,12]
        ar_tag_types: ['command','command','command','command','command','command','command','role','role','role','command']
        ar_tag_words: ['follow-me','advance','halt','rally','attention','move-forward','move-in-reverse','pedestrian','teammate','supervisor','advance']

        # GTSAM fusion variables
        role_obs_labels: ['pedestrian','teammate','supervisor']
        role_obs_model_coeffs: [1., 1., 1.,
                                1., 0., 0.,
                                0., 1., 0.,
                                0., 0., 1.]
        comm_obs_labels: ['none','advance','attention','follow-me','halt','move-forward','move-in-reverse','rally']
        comm_obs_model_coeffs: [1., 0., 0., 0., 0., 0., 0., 0.,
                                0., 1., 0., 0., 0., 0., 0., 0.,
                                0., 0., 1., 0., 0., 0., 0., 0.,
                                0., 0., 0., 1., 0., 0., 0., 0.,
                                0., 0., 0., 0., 1., 0., 0., 0.,
                                0., 0., 0., 0., 0., 1., 0., 0.,
                                0., 0., 0., 0., 0., 0., 1., 0.,
                                0., 0., 0., 0., 0., 0., 0., 1.]

    objects_of_interest: ['person']

    person:
      attributes:
        variables: ['']

      states:
        variables: ['role']
        role:
          symbol: 'r' # Letter to uniquely identify the variable in GTSAM.
          labels: ['unknown','pedestrian','robot-teammate','robot-supervisor']
          probs: [10., 1., 1., 1.]
          upper_prob_limit: .90
          lower_prob_limit: .01
      
      comms: 
        symbol: 'c' # Letter to uniquely identify the variable in GTSAM.
        labels: ['none','advance','attention','follow-me','halt','move-forward','move-in-reverse','rally']
        probs: [10., 1., 1., 1., 1., 1., 1., 1.]  
        upper_prob_limit: .90
        lower_prob_limit: .01
       
